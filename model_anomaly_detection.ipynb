{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みオートエンコーダー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPRoyfuBL31_"
   },
   "source": [
    "## GoogleDriveマウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16636,
     "status": "ok",
     "timestamp": 1636860801334,
     "user": {
      "displayName": "吉澤直明",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07141788735446552588"
     },
     "user_tz": -540
    },
    "id": "xrUirv3OL0JQ",
    "outputId": "7b74a672-4d57-4d07-9b2c-6efa6dcdfbbb"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLKX52OnMRTZ"
   },
   "source": [
    "## 必要なモジュールのインポート"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuo1geIpdDxO"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 26307,
     "status": "ok",
     "timestamp": 1636860829480,
     "user": {
      "displayName": "吉澤直明",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07141788735446552588"
     },
     "user_tz": -540
    },
    "id": "KfB318svL7yi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjoYDpDuaxdU"
   },
   "source": [
    "## データパス設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1636860832875,
     "user": {
      "displayName": "吉澤直明",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07141788735446552588"
     },
     "user_tz": -540
    },
    "id": "uMWz8__6a0Gp"
   },
   "outputs": [],
   "source": [
    "CIFAR10_path = \"/content/drive/My Drive/Colab Notebooks/autoencorder_app/data/CIFAR10/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mr5mgcAErET7"
   },
   "source": [
    "##データローダー定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23742,
     "status": "ok",
     "timestamp": 1636860858252,
     "user": {
      "displayName": "吉澤直明",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07141788735446552588"
     },
     "user_tz": -540
    },
    "id": "_noddLSsrHCj",
    "outputId": "ffc7903c-d31c-4e65-f615-ff6e8b04941b"
   },
   "outputs": [],
   "source": [
    "#CIFAR10内のautomobile画像のみ取得するためのsampler\n",
    "def get_auto_sampler(trainset):\n",
    "    target = [1] #1はautomobile。\n",
    "    mask = [s[1] in target for s in trainset] #automobileのみtrueにマスクする=maskは、automobileのみ1の重みベクトル\n",
    "\n",
    "    print('合計数：', sum(mask))\n",
    "\n",
    "    #重み付きsampler：trueの画像のみ対象にする。\n",
    "    sampler = torch.utils.data.sampler.WeightedRandomSampler(mask, len(trainset))\n",
    "\n",
    "    return sampler\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),  # (256, 256) で切り抜く。\n",
    "        transforms.CenterCrop(224),  # 画像の中心に合わせて、(224, 224) で切り抜く\n",
    "        transforms.ToTensor(),  # テンソルにする。\n",
    "        transforms.Normalize( # 標準化する。\n",
    "            mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]\n",
    "        ),  \n",
    "    ]\n",
    ")\n",
    "trainset = CIFAR10(root=CIFAR10_path, train=True, transform=transform, download=True)\n",
    "testset = CIFAR10(root=CIFAR10_path, train=False, transform=transform, download=True)\n",
    "\n",
    "#重み付きsampler\n",
    "auto_sampler = get_auto_sampler(trainset)\n",
    "\n",
    "# batch_size = 50\n",
    "batch_size = 100\n",
    "# trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, sampler=auto_sampler) #samplerはshuffleと一緒に使用できない。\n",
    "\n",
    "print('学習用データセット：',trainset.data.shape)\n",
    "print('クラス：',trainset.classes)\n",
    "\n",
    "#下記作成したtrainloaderからデータ抽出して画像確認。\n",
    "# #指定したバッチサイズ分画像を取得\n",
    "# train_iter = iter(trainloader)\n",
    "# images, labels = train_iter.next()\n",
    "\n",
    "# def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "#     npimg = img.numpy()\n",
    "#     plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# #trainloaderの画像を表示して、車のみであること確認。\n",
    "# imshow(torchvision.utils.make_grid(images)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPyqHONvhDbe"
   },
   "source": [
    "## 学習用関数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 464,
     "status": "ok",
     "timestamp": 1636860863539,
     "user": {
      "displayName": "吉澤直明",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07141788735446552588"
     },
     "user_tz": -540
    },
    "id": "mF6Ka_yngMWf"
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs, trainloader):\n",
    "    losses = []\n",
    "    output_and_label = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f'epoch: {epoch}, ', end='')\n",
    "        running_loss = 0.0\n",
    "        for counter, (img, _) in enumerate(trainloader, 1):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(img)\n",
    "\n",
    "            loss = criterion(output, img)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / counter\n",
    "\n",
    "        losses.append(avg_loss)\n",
    "\n",
    "        print('loss:', avg_loss)\n",
    "        output_and_label.append((output, img))\n",
    "\n",
    "    print('finished')\n",
    "\n",
    "    return output_and_label, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsAKUmLqhrDv"
   },
   "source": [
    "## オートエンコーダーを実装するクラス定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1636860866437,
     "user": {
      "displayName": "吉澤直明",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07141788735446552588"
     },
     "user_tz": -540
    },
    "id": "pMur2BE9hqLg"
   },
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        x = self.dec(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMzp9SJxhaWW"
   },
   "source": [
    "## エンコーダーとディコーダー定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1636860869828,
     "user": {
      "displayName": "吉澤直明",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07141788735446552588"
     },
     "user_tz": -540
    },
    "id": "jlTDKwE2MPhc"
   },
   "outputs": [],
   "source": [
    "#エンコーダー設定\n",
    "enc = torch.nn.Sequential(\n",
    "    #第一引数：入力チェンネル数、第二引数：出力チャンネル数＝画像の走査に使用するカーネルの数。\n",
    "    torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2) #カーネルサイズに2×2を指定。\n",
    ")\n",
    "\n",
    "#ディコーダー設定\n",
    "dec = torch.nn.Sequential(\n",
    "    torch.nn.ConvTranspose2d(in_channels=8, out_channels=16, kernel_size=2, stride=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.ConvTranspose2d(in_channels=16, out_channels=3, kernel_size=2, stride=2),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZz8YVghigqS"
   },
   "source": [
    "## モデルの学習学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3608206,
     "status": "ok",
     "timestamp": 1636864483987,
     "user": {
      "displayName": "吉澤直明",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07141788735446552588"
     },
     "user_tz": -540
    },
    "id": "07PF3PwNhSum",
    "outputId": "5716abac-5947-47f0-dc95-94e7c0b6121a"
   },
   "outputs": [],
   "source": [
    "model = AE(enc, dec)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "EPOCHS = 100\n",
    "# EPOCHS = 50\n",
    "#input_size = 3 * 32 * 32\n",
    "#バッチサイズ50、エポック50→0.20始まりで0.18ぐらいで終わる = 前処理で(256, 256) で切り抜き無し。\n",
    "#バッチサイズ100、エポック100→0.51始まりで0.18ぐらいで終わる = 前処理で(256, 256) で切り抜き無し。\n",
    "#バッチサイズ100、エポック100→前処理で(256, 256) で切り抜き有り実施してみる。\n",
    "\n",
    "output_and_label, losses = train(model, criterion, optimizer, EPOCHS, trainloader)\n",
    "print(\"学習終了\")\n",
    "\n",
    "# GPUで学習したモデルの保存\n",
    "save_gpu_path = \"/content/drive/My Drive/Colab Notebooks/autoencorder_app/trained_model/autoencorder_gpu.pth\"\n",
    "torch.save(model.state_dict(), save_gpu_path)\n",
    "\n",
    "# CPUに変更したモデルを保存\n",
    "save_cpu_path = \"/content/drive/My Drive/Colab Notebooks/autoencorder_app/trained_model/autoencorder_cpu.pth\"\n",
    "torch.save(model.to('cpu').state_dict(), save_cpu_path)       \n",
    "print(\"保存終了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1636678153949,
     "user": {
      "displayName": "吉澤直明",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07141788735446552588"
     },
     "user_tz": -540
    },
    "id": "JjL5deUznpQu",
    "outputId": "d2c50bb2-6326-401f-9b4e-414f631da683"
   },
   "outputs": [],
   "source": [
    "# GPUで学習したモデルの保存\n",
    "save_gpu_path = \"/content/drive/My Drive/Colab Notebooks/autoencorder_app/trained_model/autoencorder_gpu.pth\"\n",
    "torch.save(model.state_dict(), save_gpu_path)\n",
    "\n",
    "# 念の為念の為CPUに変更したものも保存\n",
    "save_cpu_path = \"/content/drive/My Drive/Colab Notebooks/autoencorder_app/trained_model/autoencorder_cpu.pth\"\n",
    "torch.save(model.to('cpu').state_dict(), save_cpu_path)       \n",
    "print(\"保存終了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILsBMd1IIkwQ"
   },
   "source": [
    "## Lossの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "error",
     "timestamp": 1636636468504,
     "user": {
      "displayName": "吉澤直明",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07141788735446552588"
     },
     "user_tz": -540
    },
    "id": "HfLBk21KIpt8",
    "outputId": "e70ad958-6edb-4904-f7e7-d0212ace3a24"
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__5jaoN7IPtK"
   },
   "source": [
    "## inputととoutputの画像比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuQqEu48IOE6"
   },
   "outputs": [],
   "source": [
    "img, org = output_and_label2[-1]\n",
    "imshow(org)\n",
    "imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMkJG5eIEgAqi5qeo0mtq1U",
   "collapsed_sections": [],
   "name": "model_anomaly_detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
